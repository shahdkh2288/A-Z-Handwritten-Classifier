{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46cefe06-96e9-4740-9155-cc701f2a5a35",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da411976-126d-4458-9e9f-f7ec098d7527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Model-building libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "# Deep Learning libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59b3ec4-f8ec-419b-b113-ab0f80ef580f",
   "metadata": {},
   "source": [
    "Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eed52d-91d1-4b3d-9335-fc9232a3b987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data\n",
    "def load_data(csv_path_: str):\n",
    "    # Load dataset\n",
    "    data = pd.read_csv(csv_path_)\n",
    "    print(data.head())\n",
    "    return data\n",
    "\n",
    "# Splitting features and labels\n",
    "def split_data(data: pd.DataFrame):\n",
    "    X = data.drop('0', axis=1)  # Features\n",
    "    y = data['0']  # Labels\n",
    "    return X, y\n",
    "\n",
    "# One-hot encoding labels\n",
    "def preprocess_labels(y: pd.Series):\n",
    "    y_encodingHot = to_categorical(y, num_classes=26)  # One-hot encode\n",
    "    return y_encodingHot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4fdba5-438b-4e1e-9dd0-72383498fe4b",
   "metadata": {},
   "source": [
    "Visualizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66268858-5b9d-4380-9660-15a64dddfe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display images\n",
    "def show_images(X: pd.DataFrame, y: pd.Series, n_images: int):\n",
    "    X_images = X.values.reshape(-1, 28, 28)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i in range(n_images):\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        plt.imshow(X_images[i], cmap=\"gray\")\n",
    "        plt.title(f\"Label: {y[i]}\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to show class distribution\n",
    "def show_classes_info(y: pd.Series):\n",
    "    print(f\"\\nNumber of unique classes: {y.nunique()}\")\n",
    "    label_counts = y.value_counts()\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=label_counts.index, y=label_counts.values, palette=\"viridis\")\n",
    "    plt.title(\"Distribution of Classes in `y`\", fontsize=16)\n",
    "    plt.xlabel(\"Classes (Alphabets)\", fontsize=14)\n",
    "    plt.ylabel(\"Count\", fontsize=14)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab686856-cd7c-47be-8e01-ceadad5ddb5f",
   "metadata": {},
   "source": [
    "Neural Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99125fe8-358b-40c3-861c-542782e36210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset for NN\n",
    "def split_dataset(X, y, test_size=0.3, val_size=0.5):\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=val_size, random_state=42)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "# Neural Network Model 1\n",
    "def build_neuralnetwork_model_1():\n",
    "    model = Sequential([\n",
    "        Input(shape=(28, 28)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(26, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Neural Network Model 2\n",
    "def build_neuralnetwork_model_2():\n",
    "    model = Sequential([\n",
    "        Input(shape=(28, 28)),\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dense(128, activation='tanh'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(26, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train and plot NN performance\n",
    "def train_and_plotNN(model, X_train, y_train, X_val, y_val, epochs=5, batch_size=32):\n",
    "    trained_model = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size)\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(trained_model.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(trained_model.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(trained_model.history['loss'], label='Training Loss')\n",
    "    plt.plot(trained_model.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return trained_model\n",
    "\n",
    "# Evaluate NN model\n",
    "def evaluate_NN(model, x_test, y_test):\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred_classes = y_pred.argmax(axis=1)\n",
    "    y_actual_classes = y_test.argmax(axis=1)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_actual_classes, y_pred_classes)\n",
    "    letter = []\n",
    "    for i in range(1, 27):\n",
    "        letter.append(chr(96 + i))\n",
    "    sns.heatmap(conf_matrix, annot=True, cmap='binary', fmt='.0f', xticklabels=letter, yticklabels=letter)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"Actual Labels\")\n",
    "    plt.show()\n",
    "\n",
    "    # F1 Score\n",
    "    f1 = f1_score(y_actual_classes, y_pred_classes, average='macro')\n",
    "    print(f\"\\nAverage F1-Score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d34da2-8c27-4268-809e-86ae0e859004",
   "metadata": {},
   "source": [
    "Test best neural network model with names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9da7917-07d6-4c24-a951-c1772046c9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_for_char(char, data, labels):\n",
    "    label = ord(char.upper()) - 65\n",
    "    char_indices = np.where(labels == label)[0]\n",
    "    index = char_indices[0]\n",
    "    image = data.iloc[index].values.reshape(28, 28).astype('float32')\n",
    "    image = image / 255.0  # Normalize\n",
    "    return image\n",
    "\n",
    "\n",
    "def test_NN_with_name(name, model, data, labels):\n",
    "    predictions = []\n",
    "    for letter in name:\n",
    "        try:\n",
    "            image = create_image_for_char(letter, data, labels)\n",
    "            final_image = image.reshape(1, 28, 28)\n",
    "            pred = model.predict(final_image)\n",
    "            pred_letter = np.argmax(pred)\n",
    "            predictions.append(pred_letter)\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            predictions.append(None)\n",
    "\n",
    "    pred_letters = []\n",
    "\n",
    "\n",
    "    for pred in predictions:\n",
    "     if pred is not None:\n",
    "        pred_letters.append(chr(pred + 65))\n",
    "\n",
    "     print(f\"Predicted letters: {''.join(pred_letters)}\")\n",
    "\n",
    "     plt.figure(figsize=(10, 1))\n",
    "    for i, letter in enumerate(name):\n",
    "       plt.subplot(1, len(name), i + 1)\n",
    "    try:\n",
    "        image = create_image_for_char(letter, data, labels)\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.title(f\"Pred: {pred_letters[i]}\")\n",
    "    except ValueError:\n",
    "        plt.title(\"NA\")\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe2116b-1351-4026-b44f-ee36ef4c9259",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a21a84-0d17-44b9-ad62-043ed38c7619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_linear_SVM(X_train, y_train, X_test, y_test):\n",
    "    print(\"\\nTraining Linear SVM using SVC...\")\n",
    "    linear_svm = SVC(kernel=\"linear\", random_state=42)\n",
    "    linear_svm.fit(X_train, y_train)\n",
    "    y_pred_linear = linear_svm.predict(X_test)\n",
    "\n",
    "    print(\"\\nLinear SVM Evaluation:\")\n",
    "    accuracy_linear = accuracy_score(y_test, y_pred_linear)\n",
    "    print(f\"Accuracy: {accuracy_linear:.4f}\")\n",
    "    print(classification_report(y_test, y_pred_linear))\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred_linear), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(\"Confusion Matrix: Linear SVM\")\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\nAverage F1 Score: {f1_score(y_test, y_pred_linear, average='weighted'):.4f}\")\n",
    "\n",
    "    # Train and evaluate Non-Linear SVM (RBF kernel)\n",
    "\n",
    "\n",
    "def train_and_evaluate_rbf_SVM(X_train, y_train, X_test, y_test):\n",
    "    print(\"\\nTraining Non-Linear SVM using RBF Kernel...\")\n",
    "    rbf_svm = SVC(kernel=\"rbf\", random_state=42)\n",
    "    rbf_svm.fit(X_train, y_train)\n",
    "    y_pred_rbf = rbf_svm.predict(X_test)\n",
    "\n",
    "    print(\"\\nNon-Linear SVM (RBF Kernel) Evaluation:\")\n",
    "    accuracy_rbf = accuracy_score(y_test, y_pred_rbf)\n",
    "    print(f\"Accuracy: {accuracy_rbf:.4f}\")\n",
    "    print(classification_report(y_test, y_pred_rbf))\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred_rbf), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(\"Confusion Matrix: Non-Linear SVM (RBF Kernel)\")\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\nAverage F1 Score: {f1_score(y_test, y_pred_rbf, average='weighted'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d9ef30-8d02-4426-8c07-184c49871d11",
   "metadata": {},
   "source": [
    "Logistic Regression Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af94cce-c1f5-469d-9619-cade78a84f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.001, n_iters=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.classes = None\n",
    "        self.training_loss = []\n",
    "        self.training_accuracy = []\n",
    "        self.validation_loss = []\n",
    "        self.validation_accuracy = []\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.classes = np.unique(y)  # Find all unique classes\n",
    "        n_classes = len(self.classes)\n",
    "\n",
    "        # Initialize weights and biases for each class\n",
    "        self.weights = np.zeros((n_classes, n_features))\n",
    "        self.bias = np.zeros(n_classes)\n",
    "\n",
    "        # Train one model per class (One-vs-All)\n",
    "        for idx, c in enumerate(self.classes):\n",
    "            y_binary = (y == c).astype(int)  # Convert labels to binary for this class\n",
    "\n",
    "            for _ in range(self.n_iters):\n",
    "                linear_model = np.dot(X, self.weights[idx]) + self.bias[idx]\n",
    "                y_predicted = self._sigmoid(linear_model)\n",
    "\n",
    "                # Compute gradients\n",
    "                dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y_binary))\n",
    "                db = (1 / n_samples) * np.sum(y_predicted - y_binary)\n",
    "\n",
    "                # Update parameters\n",
    "                self.weights[idx] -= self.lr * dw\n",
    "                self.bias[idx] -= self.lr * db\n",
    "\n",
    "                # Calculate training loss and accuracy\n",
    "                loss = -np.mean(y_binary * np.log(y_predicted + 1e-9) + (1 - y_binary) * np.log(1 - y_predicted + 1e-9))\n",
    "                accuracy = np.mean((y_predicted >= 0.5) == y_binary)\n",
    "\n",
    "                if len(self.training_loss) < self.n_iters:\n",
    "                    self.training_loss.append(loss)\n",
    "                    self.training_accuracy.append(accuracy)\n",
    "\n",
    "                # Validation loss and accuracy\n",
    "                if X_val is not None and y_val is not None:\n",
    "                    y_val_binary = (y_val == c).astype(int)\n",
    "                    val_linear_model = np.dot(X_val, self.weights[idx]) + self.bias[idx]\n",
    "                    y_val_predicted = self._sigmoid(val_linear_model)\n",
    "                    val_loss = -np.mean(\n",
    "                        y_val_binary * np.log(y_val_predicted + 1e-9) +\n",
    "                        (1 - y_val_binary) * np.log(1 - y_val_predicted + 1e-9)\n",
    "                    )\n",
    "                    val_accuracy = np.mean((y_val_predicted >= 0.5) == y_val_binary)\n",
    "\n",
    "                    if len(self.validation_loss) < self.n_iters:\n",
    "                        self.validation_loss.append(val_loss)\n",
    "                        self.validation_accuracy.append(val_accuracy)\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_model = np.dot(X, self.weights.T) + self.bias\n",
    "        probabilities = self._sigmoid(linear_model)\n",
    "        return self.classes[np.argmax(probabilities, axis=1)]  # Pick class with highest probability\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        y_pred = self.predict(X_test)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        avg_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "        acc = np.mean(y_pred == y_test)\n",
    "        return cm, avg_f1, acc\n",
    "\n",
    "    def plot_curves(self):\n",
    "        plt.figure(figsize=(12, 5))\n",
    "\n",
    "        # Loss curve\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(self.training_loss, label='Training Loss')\n",
    "        if self.validation_loss:\n",
    "            plt.plot(self.validation_loss, label='Validation Loss')\n",
    "        plt.title('Loss Curve')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        # Accuracy curve\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(self.training_accuracy, label='Training Accuracy')\n",
    "        if self.validation_accuracy:\n",
    "            plt.plot(self.validation_accuracy, label='Validation Accuracy')\n",
    "        plt.title('Accuracy Curve')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e145f0c-42da-4f97-aa4b-e7ae75306f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92371f2-a69e-4589-965d-98756cb81932",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    csv_path = \"../input/az-handwritten-alphabets-in-csv-format/A_Z Handwritten Data.csv\"\n",
    "    data = load_data(csv_path)\n",
    "    X, y = split_data(data)\n",
    "\n",
    "    # Show Class Distribution and Sample Images\n",
    "    show_classes_info(y)\n",
    "\n",
    "    show_images(X, y, 10)\n",
    "\n",
    "    # Normalize Data\n",
    "    X_normalized = X.to_numpy(dtype=\"float32\") / 255.0\n",
    "    print(f\"\\nX_normalized shape: {X_normalized.shape}\")\n",
    "\n",
    "    # .....................................\n",
    "\n",
    "    y_encoded = preprocess_labels(y)\n",
    "\n",
    "    X_normalized_reshaped = X_normalized.reshape(-1, 28, 28)\n",
    "\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_dataset(X_normalized_reshaped, y_encoded)\n",
    "\n",
    "    # Train and Evaluate Model 1\n",
    "    print(\"\\nTraining Model 1:\")\n",
    "    model1 = build_neuralnetwork_model_1()\n",
    "    training1 = train_and_plotNN(model1, X_train, y_train, X_val, y_val)\n",
    "    print(\"\\nEvaluating Model 1:\")\n",
    "    evaluate_NN(model1, X_test, y_test)\n",
    "\n",
    "    # ...................................\n",
    "\n",
    "    # Train and Evaluate Model 2\n",
    "    print(\"\\nTraining Model 2:\")\n",
    "    model2 = build_neuralnetwork_model_2()\n",
    "    training2 = train_and_plotNN(model2, X_train, y_train, X_val, y_val)\n",
    "    print(\"\\nEvaluating Model 2:\")\n",
    "    evaluate_NN(model2, X_test, y_test)\n",
    "    # ...............................................\n",
    "\n",
    "    # save best model\n",
    "    if training2.history['val_accuracy'][-1] > training1.history['val_accuracy'][-1]:\n",
    "        model2.save('best_nn_model.h5')\n",
    "        print(\"Model 2 is the best model.\")\n",
    "        best_model = model2\n",
    "    else:\n",
    "        model1.save('best_nn_model.h5')\n",
    "        print(\"Model 1 is the best model.\")\n",
    "        best_model = model1\n",
    "    # ...........................................\n",
    "    # reload best model\n",
    "    best_model = keras.models.load_model('best_nn_model.h5')\n",
    "    evaluate_NN(best_model, X_test, y_test)\n",
    "    name = \"Shahd\"\n",
    "    name1 = \"Aliaa\"\n",
    "    name2 = \"Nahla\"\n",
    "    test_NN_with_name(name, best_model, X, y)\n",
    "    test_NN_with_name(name1, best_model, X, y)\n",
    "    test_NN_with_name(name2, best_model, X, y)\n",
    "    #......................................................\n",
    "\n",
    "    # Apply PCA to reduce dimensionality\n",
    "    print(\"\\nApplying PCA...\")\n",
    "    pca = PCA(0.95)  # Retain 95% of the variance\n",
    "    X_pca = pca.fit_transform(X_normalized)\n",
    "    print(f\"X_pca shape: {X_pca.shape}\")\n",
    "    print(f\"Explained variance ratio: {np.sum(pca.explained_variance_ratio_):.2f}\")\n",
    "\n",
    "    # Split data into training and testing sets (70% training, 30% testing)\n",
    "    X_train1, X_test1, y_train1, y_test1 = train_test_split(\n",
    "        X_pca, y, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"\\nX_train shape: {X_train1.shape}, y_train shape: {y_train1.shape}\")\n",
    "    print(f\"X_test shape: {X_test1.shape}, y_test shape: {y_test1.shape}\")\n",
    "    train_and_evaluate_rbf_SVM(X_train1, y_train1, X_test1, y_test1)\n",
    "\n",
    "    #.................................................................................\n",
    "\n",
    "    test_sample_size = 50000  # Set the number of test samples to use for evaluation\n",
    "    train_sample_size = 50000  # Set the number of training samples to use for training\n",
    "\n",
    "    # Split the data into training, validation, and testing datasets\n",
    "    X_train2, X_temp2, y_train2, y_temp2 = train_test_split(X_normalized, y, test_size=0.4, random_state=42)\n",
    "    X_val2, X_test2, y_val2, y_test2 = train_test_split(X_temp2, y_temp2, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Use only a subset of the training data for training\n",
    "    X_train_subset = X_train2[:train_sample_size]\n",
    "    y_train_subset = y_train2[:train_sample_size]\n",
    "\n",
    "    # Use only a subset of the test data for evaluation\n",
    "    X_test_subset = X_test2[:test_sample_size]\n",
    "    y_test_subset = y_test2[:test_sample_size]\n",
    "\n",
    "    # Initialize and train the model\n",
    "    model = LogisticRegression(learning_rate=0.05, n_iters=2000)\n",
    "    model.fit(X_train_subset, y_train_subset, X_val2, y_val2)  # Train on the subset of the training data\n",
    "\n",
    "    # Plot training and validation curves\n",
    "    model.plot_curves()\n",
    "\n",
    "    # Evaluate the model on the subset of the test set\n",
    "    confusion_matrix, avg_f1_score, accuracy = model.evaluate(X_test_subset, y_test_subset)\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix)\n",
    "    print(\"Average F1 Score:\", avg_f1_score)\n",
    "    print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
